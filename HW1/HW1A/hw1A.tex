\documentclass[]{article}
\usepackage{amsmath}\usepackage{amsfonts}
\usepackage[margin=1in,footskip=0.25in]{geometry}
\usepackage{mathtools}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage[final]{graphicx}
\usepackage{listings}
\usepackage{courier}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

% \usepackage{wrapfig}
\graphicspath{{.}}
\begin{document}

\begin{center}
    CSE 546 SPRING 2021: HW1 
\end{center}
\begin{center}
    Name: Honda Li
\end{center}

\section*{Short Answer and ``True or False'' Conceptual Questions}
    \subsection*{A.0}
        \subsubsection*{(A.0.a)}
            \hspace{1.1em}
            The bias and variance is similar to the concepts of precision and accuracy in Experimental Physics. Under the context of machine learning, Bias refers to part of the learning errors caused by a model being too simple, in a way that it just cant represent the joint probability density function with its simplicity. 
            \par
            The variance refers to the variance of the random variable $\hat{f}(x)$, which depends on the samples we observed. 
            \par
            Bias-variance trade off relates 2 types of learning errors (Bias, Variance) with the model complexity. 
        \subsubsection*{(A.0.b)}
            \hspace{1.1em}
            Usually, higher the model complexity, higher the variance, lower the model complexity, higher the bias. 
        \subsubsection*{(A.0.c)}
            \hspace{1.1em}
            False. The bias decreases. Because the bias is: $\mathbb{E}\left[
                \left(
                f(x) - \mathbb{E}\left[\hat{f}(x)\right]
                \right)^2
            \right]$. The number of sample seems to be irrelevant to the amount of bias we have for the model. 
        \subsubsection*{(A.0.d)}
            \hspace{1.1em}
            True when we fix the model complexity. This is absolutely true when we consider a linear regression. If we take infinitely many data, the best line-fit will converge. 
            \par
            This is even more true when we just consider taking the average as a way of making prediction (Which is not a bad way to predict the output given $X = x$), then, this is literally the Central limit theorem, as we have more and more samples, the variance of the sample average gets smaller. 
        \subsubsection*{(A.0.e)}

        \subsubsection*{(A.0.f)}
            \hspace{1.1em}
            We should use the test set to tune the hyper-parameters for the models. 
        \subsubsection*{(A.0.g)}
            \hspace{1.1em}
            False. It's an underestimate. 

\section*{Maximum Likelihood Estimator(MLE)}
    \subsection*{(A.1)}
        \subsubsection*{(A.1.a)}\label{A.1.a}
            \hspace{1.1em}
            \textbf{Objective}: Find the expression for the maximum=likelihood estimate for the parameter $\lambda$ for the poisson distribution, interns of the goal count. Assume idd rvs. 
            \par
            Here we will assume that observations obtained takes the form $x_1, x_2, \cdots x_N$, and then we derive the best estimator for $\lambda$ in this much general context. 
            \par
            I will shut up and just show you the math: 
            \begin{align*}\tag{A.1.a.1}\label{eqn:A.1.a.1}
                & 
                \prod_{n = 1}^{N} 
                \text{Poi}(x_n|\lambda)
                \\
                &
                \sum_{n = 1}^{N}
                \log\left(
                    \text{Poi}(x_n|\lambda)
                \right)
                \\
                &
                \sum_{n = 1}^{N}
                \left(
                    -\lambda + x_n\ln(\lambda) + \log(x_n!)
                \right)
            \end{align*}
            Notice that, only some of the terms are relevant to the parameter $\lambda$, therefore, the optimization problem we are solving is: 
            \begin{equation*}\tag{A.1.a.2}\label{eqn:A.1.a.2}
                \lambda^+ = 
                \underset{\lambda}{\text{argmax}}
                \left\lbrace
                    -N\lambda
                    +  
                    \ln(\lambda)
                    \sum_{i = 1}^{N}
                        \left(
                            x_n
                        \right)
                \right\rbrace
            \end{equation*}
            To solve it, we just take the derivative, set it to zero and then solve for $\lambda$, because this function is a function that has a single local maximum. 
            \begin{align*}\tag{A.1.a.3}\label{eqn:A.1.a.3}
                \partial_\lambda \left[
                -N\lambda
                +  
                \ln(\lambda)
                \sum_{i = 1}^{N}
                    \left(
                        x_n
                    \right)
                \right] =& 0
                \\
                -N + \frac{\sum_{n = 1}^{N}x_n}{
                \lambda^+
                } =& 0 
                \\
                \implies
                \lambda^+ =& \frac{\sum_{n = 1}^{N}x_n}{N}
            \end{align*}
            Therefor, for this particular problem, the best estimator will be the average of all the observation, which is just: 
            $$
                \frac{2 + 4 + 6 + 1}{5} = 2.6
            $$
            And that is the answer for the question. 
        \subsubsection*{(A.1.b)}\label{A.1.b}
            \hspace{1.1em}
            The derivation of the best estimator in the general context is shown in \hyperref[A.1.a]{A.1.a}. 
            \par
            The numerical value for six observations is: 
            $$
                \frac{2 + 4 + 6 + 1 + 3}{7} = 2.6666666666\cdots
            $$
        \subsubsection*{(A.1.c)}
            The numerical results for 5 observations has been shown in \hyperref[A.1.a]{A.1.a} and \hyperref[A.1.b]{A.1.b} respectively. 
            
    \subsection*{(A.2)}
        \hspace{1.1em}
        \textbf{Objective: } Find the MLE for the uniform distribution on $[o, \theta]$, where $\theta$ is the value we want to estimate.
        \par
        Suppose that an observations has been made: $x_1, x_2, \cdots x_N$, and we assume that they are idd, and we want to find the likelihood of such an observation is generated using the Uniform distribution. And this will be given by the expression: 
        \begin{equation*}\tag{A.2.1}\label{eqn:A.2.1}
            \prod_{n = 1}^{N} 
            \underbrace{
            \mathbb{P}\left(X = x_n\right)}_{\frac{1}{\theta}\mathbf{1}\{0 \le x_n \le \theta\}}
        \end{equation*}
        \par
        Observe that, if any of the observation is beyond the range $[0, \theta]$, we will have zero likelihood, so let's assume that $\theta \le \max_{1\le i \le N}(x_i)$, then we will have this expression for the likelihood: 
        \begin{equation*}\tag{A.2.2}\label{eqn:A.2.2}
            \prod_{n = 1}^{N} 
            \frac{1}{\theta} = \frac{1}{\theta^N}
        \end{equation*}
        And taking the log on that we have: 
        \begin{equation*}\tag{A.2.3}\label{eqn:A.2.3}
            \log\left(\frac{1}{\theta^N}\right) = -N\log(\theta)
        \end{equation*}
        \par
        Observe that that function is monotonically decreasing as the value of $\theta$ get larger and larger, therefore, to maximize the likelihood, we need the value of $\theta$ to be as small as possible, and the smallest possible such $\theta$ that is not giving us zero likelihood is: $\max_{1\le i \le N}(x_i)$, therefore, best estimate is given by: 
        $$
            \theta^+ =\max_{1\le i \le N}(x_i)
        $$

\section*{Over-fitting}
    \subsection*{A.3}
        \begin{enumerate}
        \item[1.] $S = \{(x_i, y_i)\}_{i = 1}^N$ drawn from idd with underlying joint distribution $\mathcal{D}$. 
        \item[2.] The training set is break into $S_\text{train}, S_\text{test}$, and $S = S_\text{Train} \cup S_\text{Test}$, notice that overlapping is possible. 
        \item[3.] And the true least square error, given a predictive model $f$ is: $\epsilon(f) = \mathbb{E}\left[(f(x) d - y)^2\right]$. 
        \end{enumerate}
    \subsubsection*{A.3.a}
        We want to show that that, the expected bias of the model $f$ over the training set and the test set is the same as expected value of the bias over the distribution $\mathcal{D}$, hence it's unbiased. 
        \\[1em]
        Start by considering the expected value of $\epsilon_\text{train}(f)$: 
        \begin{align*}\tag{A.3.a.1}\label{eqn:A.3.a.1}
            & \mathbb{E}_{\text{train}}\left[\frac{1}{N_\text{train}}
            \sum_{(x, y)\in S_\text{train}}^{}\left(
                f(x) - y
            \right)^2\right]
            \\
            = &
            \frac{1}{N_\text{train}} 
            \sum_{(x, y)\in S_\text{train}}^{}
            \underbrace{
                \mathbb{E}_{\text{train}}
                \left[ 
                \left(
                    f(x) - y
                \right)^2\right]
            }_{\epsilon(f)}
            \\
            \hat{\epsilon}(f)
            = &
            \hat{\epsilon}_{\text{train}}(f)
        \end{align*}
        For each term $f(x) - y$, we assume that it's idd, and therefore, its expected value is going to be the same as if it's drawn from the distribution $\mathcal{D}$, because each sample of the train set is drawn in this way, therefore, we can conclude that $\mathbb{E}\left[(f(x) - y)^2\right]$ is going to give $\epsilon(f)$. 
        \\[1em]
        The proof for $\hat{\epsilon}_\text{test}(f)$ is going to be exact same because they are both drawn from the same idd joint distribution: $\mathcal{D}$. And hence we know that the bias estimator for any given model is going to be unbiased. 
    \subsubsection*{A.3.b}
        $\mathbb{E}_{\text{train}}\left[\hat{\epsilon}_\text{train}(\hat{f})\right]\ne \mathbb{E}\left[\epsilon(\hat{f})\right]$ Consider Linear regression where 2 the sample size is so small ($d - 1$ samples where $d$ is the number of features) that we have a perfect fit model $\hat{f}$ then the bias of the model is going to be zero under the training set, however, the bias over the real distribution is not, because $\mathcal{D}$ could be non-linear and there could be noises, which both will introduce some biased. 
    \subsubsection*{A.3.c}

\section*{Polynomial Regression}

\section*{Ridge Regression on MNIST}

\end{document}