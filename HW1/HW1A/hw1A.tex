\documentclass[]{article}
\usepackage{amsmath}\usepackage{amsfonts}
\usepackage[margin=1in,footskip=0.25in]{geometry}
\usepackage{mathtools}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage[final]{graphicx}
\usepackage{listings}
\usepackage{courier}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

% \usepackage{wrapfig}
\graphicspath{{.}}
\begin{document}

\begin{center}
    CSE 546 SPRING 2021: HW1 
\end{center}
\begin{center}
    Name: Honda Li
\end{center}

\section*{Short Answer and ``True or False'' Conceptual Questions}
    \subsection*{A.0}
        \subsubsection*{(A.0.a)}
            The bias and variance is similar to the concepts of precision and accuracy in Experimental Physics. Under the context of machine learning, Bias refers to part of the learning errors caused by a model being too simple, in a way that it just cant represent the joint probability density function with its simplicity. 
            \\[1em]
            The variance refers to the variance of the random variable $\hat{f}(x)$, which depends on the samples we observed. 
            \\[1em]
            Bias-variance trade off relates 2 types of learning errors (Bias, Variance) with the model complexity. 
        \subsubsection*{(A.0.b)}
            Usually, higher the model complexity, higher the variance, lower the model complexity, higher the bias. 
        \subsubsection*{(A.0.c)}
            False. The bias decreases. Because the bias is: $\mathbb{E}\left[
                \left(
                f(x) - \mathbb{E}\left[\hat{f}(x)\right]
                \right)^2
            \right]$. The number of sample seems to be irrelevant to the amount of bias we have for the model. 
        \subsubsection*{(A.0.d)}
            True when we fix the model complexity. This is absolutely true when we consider a linear regression. If we take infinitely many data, the best line-fit will converge. 
            \\[1em]
            This is even more true when we just consider taking the average as a way of making prediction (Which is not a bad way to predict the output given $X = x$), then, this is literally the Central limit theorem, as we have more and more samples, the variance of the sample average gets smaller. 
        \subsubsection*{(A.0.e)}
            Yes, and this is exactly the idea behind regularization, where it tries to change the objective of the optimization problem a bit, allowing the models to use less features and prevent it from over-fitting. 
        \subsubsection*{(A.0.f)}
            We should use the test set to tune the hyper-parameters for the models. This is true because the test set is indicative of true performance of the model. 
            \\
            Consider hypertunning the polynomial regression using training set only, where $p$ is the degree of polynomial. Then, for any given sample that is normalized, there is a $p = n$ that where $n$ is the total number of samples and th polynomial will fit perfectly. This is obviously over-fitting. Hence we should hypertune using the test data set. 
        \subsubsection*{(A.0.g)}
            False. It's an underestimate. This is a conclusion from the lecture. 

\section*{Maximum Likelihood Estimator(MLE)}
    \subsection*{(A.1)}
        \subsubsection*{(A.1.a)}\label{A.1.a}
            \textbf{Objective}: Find the expression for the maximum=likelihood estimate for the parameter $\lambda$ for the poisson distribution, interns of the goal count. Assume idd rvs. 
            \\[1em]
            Here we will assume that observations obtained takes the form $x_1, x_2, \cdots x_N$, and then we derive the best estimator for $\lambda$ in this much general context. 
            \\[1em]
            I will shut up and just show you the math: 
            \begin{align*}\tag{A.1.a.1}\label{eqn:A.1.a.1}
                & 
                \prod_{n = 1}^{N} 
                \text{Poi}(x_n|\lambda)
                \\
                &
                \sum_{n = 1}^{N}
                \log\left(
                    \text{Poi}(x_n|\lambda)
                \right)
                \\
                &
                \sum_{n = 1}^{N}
                \left(
                    -\lambda + x_n\ln(\lambda) + \log(x_n!)
                \right)
            \end{align*}
            Notice that, only some of the terms are relevant to the parameter $\lambda$, therefore, the optimization problem we are solving is: 
            \begin{equation*}\tag{A.1.a.2}\label{eqn:A.1.a.2}
                \lambda^+ = 
                \underset{\lambda}{\text{argmax}}
                \left\lbrace
                    -N\lambda
                    +  
                    \ln(\lambda)
                    \sum_{i = 1}^{N}
                        \left(
                            x_n
                        \right)
                \right\rbrace
            \end{equation*}
            To solve it, we just take the derivative, set it to zero and then solve for $\lambda$, because this function is a function that has a single local maximum. 
            \begin{align*}\tag{A.1.a.3}\label{eqn:A.1.a.3}
                \partial_\lambda \left[
                -N\lambda
                +  
                \ln(\lambda)
                \sum_{i = 1}^{N}
                    \left(
                        x_n
                    \right)
                \right] =& 0
                \\
                -N + \frac{\sum_{n = 1}^{N}x_n}{
                \lambda^+
                } =& 0 
                \\
                \implies
                \lambda^+ =& \frac{\sum_{n = 1}^{N}x_n}{N}
            \end{align*}
            Therefor, for this particular problem, the best estimator will be the average of all the observation, which is just: 
            $$
                \frac{2 + 4 + 6 + 1}{5} = 2.6
            $$
            And that is the answer for the question. 
        \subsubsection*{(A.1.b)}\label{A.1.b}
            The derivation of the best estimator in the general context is shown in \hyperref[A.1.a]{A.1.a}. 
            \\[1em]
            The numerical value for six observations is: 
            $$
                \frac{2 + 4 + 6 + 1 + 3}{7} = 2.6666666666\cdots
            $$
        \subsubsection*{(A.1.c)}
            The numerical results for 5 observations has been shown in \hyperref[A.1.a]{A.1.a} and \hyperref[A.1.b]{A.1.b} respectively. 
            
    \subsection*{(A.2)}
        \textbf{Objective: } Find the MLE for the uniform distribution on $[o, \theta]$, where $\theta$ is the value we want to estimate.
        \\[1em]
        Suppose that an observations has been made: $x_1, x_2, \cdots x_N$, and we assume that they are idd, and we want to find the likelihood of such an observation is generated using the Uniform distribution. And this will be given by the expression: 
        \begin{equation*}\tag{A.2.1}\label{eqn:A.2.1}
            \prod_{n = 1}^{N} 
            \underbrace{
            \mathbb{P}\left(X = x_n\right)}_{\frac{1}{\theta}\mathbf{1}\{0 \le x_n \le \theta\}}
        \end{equation*}
        \\[1em]
        Observe that, if any of the observation is beyond the range $[0, \theta]$, we will have zero likelihood, so let's assume that $\theta \le \max_{1\le i \le N}(x_i)$, then we will have this expression for the likelihood: 
        \begin{equation*}\tag{A.2.2}\label{eqn:A.2.2}
            \prod_{n = 1}^{N} 
            \frac{1}{\theta} = \frac{1}{\theta^N}
        \end{equation*}
        And taking the log on that we have: 
        \begin{equation*}\tag{A.2.3}\label{eqn:A.2.3}
            \log\left(\frac{1}{\theta^N}\right) = -N\log(\theta)
        \end{equation*}
        \\[1em]
        Observe that that function is monotonically decreasing as the value of $\theta$ get larger and larger, therefore, to maximize the likelihood, we need the value of $\theta$ to be as small as possible, and the smallest possible such $\theta$ that is not giving us zero likelihood is: $\max_{1\le i \le N}(x_i)$, therefore, best estimate is given by: 
        $$
            \theta^+ =\max_{1\le i \le N}(x_i)
        $$

\section*{Over-fitting}
    \subsection*{A.3}
        \begin{enumerate}
        \item[1.] $S = \{(x_i, y_i)\}_{i = 1}^N$ drawn from idd with underlying joint distribution $\mathcal{D}$. 
        \item[2.] The training set is break into $S_\text{train}, S_\text{test}$, and $S = S_\text{Train} \cup S_\text{Test}$, notice that overlapping is possible. 
        \item[3.] And the true least square error, given a predictive model $f$ is: $\epsilon(f) = \mathbb{E}\left[(f(x) d - y)^2\right]$. 
        \end{enumerate}
    \subsubsection*{A.3.a}
        We want to show that that, the expected bias of the model $f$ over the training set and the test set is the same as expected value of the bias over the distribution $\mathcal{D}$, hence it's unbiased. 
        \\[1em]
        Start by considering the expected value of $\epsilon_\text{train}(f)$: 
        \begin{align*}\tag{A.3.a.1}\label{eqn:A.3.a.1}
            & \mathbb{E}_{\text{train}}\left[\frac{1}{N_\text{train}}
            \sum_{(x, y)\in S_\text{train}}^{}\left(
                f(x) - y
            \right)^2\right]
            \\
            = &
            \frac{1}{N_\text{train}} 
            \sum_{(x, y)\in S_\text{train}}^{}
            \underbrace{
                \mathbb{E}_{\text{train}}
                \left[ 
                \left(
                    f(x) - y
                \right)^2\right]
            }_{\epsilon(f)}
            \\
            \hat{\epsilon}(f)
            = &
            \hat{\epsilon}_{\text{train}}(f)
        \end{align*}
        For each term $f(x) - y$, we assume that it's idd, and therefore, its expected value is going to be the same as if it's drawn from the distribution $\mathcal{D}$, because each sample of the train set is drawn in this way, therefore, we can conclude that $\mathbb{E}\left[(f(x) - y)^2\right]$ is going to give $\epsilon(f)$. 
        \\[1em]
        The proof for $\hat{\epsilon}_\text{test}(f)$ is going to be exact same because they are both drawn from the same idd joint distribution: $\mathcal{D}$. And hence we know that the bias estimator for any given model is going to be unbiased. Since both has the same variance we know that: 
        \begin{equation*}\tag{A.3.a.2}\label{eqn:A.3.a.2}
            \mathbb{E}_\text{train}\left[\hat{\epsilon}_\text{train}(f)\right]
            =
            \mathbb{E}_\text{test}\left[\hat{\epsilon}_\text{test}(f)\right]
            =
            \hat{\epsilon}(f) 
        \end{equation*}
    \subsubsection*{A.3.b}
        $\mathbb{E}_{\text{train}}\left[\hat{\epsilon}_\text{train}(\hat{f})\right]\ne \mathbb{E}\left[\epsilon(\hat{f})\right]$ Consider Linear regression where 2 the sample size is so small ($d - 1$ samples where $d$ is the number of features) that we have a perfect fit model $\hat{f}$ then the bias of the model is going to be zero under the training set, however, the bias over the real distribution is not, because $\mathcal{D}$ could be non-linear and there could be noises, which both will introduce some biased. 
    \subsubsection*{A.3.c}
        Some explanations are needed for this question. Consider the following expression: 
        \begin{equation*}\tag{A.3.c.1}\label{eqn:A.3.c.1}
            \mathbb{E}_\text{train} 
            \left[\hat{\epsilon}_\text{train}(\hat{f}_\text{train})\right]
            \le
            \mathbb{E}_{\text{train, test }}\left[
                \hat{\epsilon}_\text{test}
                (\hat{f}_\text{train})
            \right]
        \end{equation*}
        This is saying that, the expected value of the error on trained estimator evaluated using the test samples by enumerating over all the test samples is less than The expected value of the error when we train the model with train set and get the error with the test set. 
        The estimator of the model is obtained via the following procedures: 
        \\[1em]
        Let $\mathcal{F} = \{f_1, f_2\cdots\}$ be a collection of functions and $\hat{f}$ will minimizes the error given the training set. Now let's consider the error the expected value of the error on the test set of the estimator obtained from the train set: 
        \begin{align*}\tag{A.3.c.2}\label{eqn:A.3.c.2}
            \mathbb{E}_{\text{train, test }}\left[
                \hat{\epsilon}_\text{test}
                (\hat{f}_\text{train})
            \right]\beta
            = &
            \sum_{f\in\mathcal{F}}^{}\mathbb{E}_\text{train, test}
            \left[
                \hat{\epsilon}_{\text{\text{test}}}(f)\mathbf{1}\{\hat{f}_\text{train} = f\}
            \right]
            \\
            \underset{\text{(1)}}{=} &
            \sum_{f\in\mathcal{F}}^{}
            \mathbb{E}_\text{test}\left[
                \hat{\epsilon}(f)
            \right]
            \mathbb{E}_\text{train}\left[\epsilon_\text{test}
                \mathbf{1}\{\hat{f}_\text{train} = f\}
            \right]
            \\
            = &
            \sum_{f\in\mathcal{F}}^{}
            \mathbb{E}_\text{test}\left[
                \hat{\epsilon}_\text{test}(f)
            \right]
            \mathbb{P}\left(
                \hat{f}_\text{train} = f
            \right)
            \\
            = &
            \mathbb{E}_\text{test}\left[
                \hat{\epsilon}_\text{test}(f)
            \right]
            \\
            \underset{\text{(2)}}{=}&
            \mathbb{E}_\text{train}\left[
                \hat{\epsilon}_\text{train}(f)
            \right]
        \end{align*}
        (1) This is by the independence between the test and the training set, therefore, 2 random variable based on each one them can have the expected value operator distributes over. (2) this is by results from \hyperref[eqn:A.3.a.2]{A.3.a.2}. Now, by the definition that $\hat{f}$ minimizes the error compare to all other models on the training setm then by definition, the expected value of it is going to keep the inequality, therefore: 
        \begin{align*}\tag{A.3.c.1}\label{eqn:A.3.c.1}
            & \hat{f} = \min_{f\in\mathcal{F}} \hat{\epsilon}_\text{train}(f)
            \\
            \implies & 
            \mathbb{E}_\text{train} 
            \left[\hat{\epsilon}_\text{train}(\hat{f}_\text{train})\right]
            \le 
            \mathbb{E}_\text{train}\left[
                \hat{\epsilon}_\text{train}(f)
            \right]
            =
            \mathbb{E}_{\text{train, test }}\left[
                \hat{\epsilon}_\text{test}
                (\hat{f}_\text{train})
            \right]
        \end{align*}
        And this is what we want to show for this problem. 
\section*{Polynomial Regression}
        
\section*{Ridge Regression on MNIST}

\end{document}