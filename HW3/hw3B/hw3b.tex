\documentclass[]{article}
\usepackage{amsmath}\usepackage{amsfonts}
\usepackage[margin=1in,footskip=0.25in]{geometry}
\usepackage{mathtools}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage[final]{graphicx}
\usepackage{listings}
\usepackage{courier}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

% \usepackage{wrapfig}
\graphicspath{{.}}

\begin{document}
\begin{center}
    Name: Honda Li \quad Class: CSE 546 SPRING 2021\quad HW3B 
\end{center}


\section*{B.1: Intro to Sample Complexity}
    \subsection*{B.1.a}
        Let's exam the statement: 
        \begin{align*}\tag{B.1.a}\label{eqn:B.1.a}
            \mathbb{P}\left[
                \hat{R}_n(f) = 0
            \right]
            &= 
            \mathbb{P}\left[
                \frac{1}{n}\sum_{i = 1}^{n}
                    \mathbf{1}\{
                        f(x_i) \ne y_i
                    \} = 0
            \right]
            \\
            &= 
            \prod_{i = 1}^{n}
                1 - \mathbb{P}\left[
                    f(x_i) \ne y_i
                \right]
        \end{align*}
    Let's use the statement in the hypothesis. The statement was $R(f) > \epsilon$, which describes the event that $\mathbb{E}\left[\mathbf{1}\{f(x)\ne Y\}\right]$. so then $1 - R(f)$ describes exepected value of the event that: $1 - \mathbb{P}\left(f(x_i) \ne y\right)$. And notice that $1 - R(f)< 1 - \epsilon < \exp(epsilon)$, so then we can simplify the above expression into: 
    \begin{align*}\tag{B.1.a.1}\label{eqn:B.1.a.1}
        \prod_{i = 1}^{n}
        1 - \mathbb{P}\left[
            f(x_i) \ne y_i
        \right] = (1 - R(f)) \le (\exp(\epsilon))^n = \exp(n\epsilon)
        \\
        \implies 
        \mathbb{P}\left[
            \hat{R}_n(f) = 0
        \right] \le \exp(n\epsilon)
    \end{align*}

    \subsection*{B.1.b}    
        The results from the previous involves the hypothesis that $R(f)\ge \epsilon$, the theoretical risk of the model is larger than $\epsilon$, therefore, under a larger scope the more appropriate inequality to make should be: 
        \begin{align*}\tag{B.1.b.1}\label{eqn:B.1.b.1}
            \mathbb{P}\left[
                \hat{R}_n(f) = 0\wedge R(f) \ge \epsilon
            \right] \le \exp(-n\epsilon)
        \end{align*}
        For the proof, let's start with the following statement: 
        \begin{align*}\tag{B.1.b.2}\label{eqn:B.1.b.2}
            \mathbb{P}\left[
                f(f) > \epsilon \wedge \hat{R}_n(f) = 0
            \right] &= 
            \mathbb{P}\left[\left.
                \hat{R}_n(f) = 0 \right|R(f) > \epsilon
            \right]\mathbb{P}\left[
                R(f)> \epsilon
            \right]
            \\
            \implies \mathbb{P}\left[
                f(f) > \epsilon \wedge \hat{R}_n(f) = 0
            \right]&\le \mathbb{P}\left[\left.
                \hat{R}_n(f) = 0 \right|R(f) > \epsilon
            \right] \le \exp(-n\epsilon)
        \end{align*}
        Now, the statement $\exists f\in \mathcal{F}: R(f)> \epsilon \wedge \hat{R}_n(f) = 0$ implies that occurence of at least one $f$ that make the event true, hence, it's the union of the probability of each individual $f$ in $\mathcal{F}$ which can make it true. 
        \begin{align*}\tag{B.1.b.3}\label{eqn:B.1.b.3}
            \mathbb{P}\left[
                \exists f \in \mathcal{F}: R(f) > \epsilon \wedge \hat{R}_n(f) = 0 
            \right] 
            &=
            \mathbb{P}\left[
                \bigcup_{f\in \mathcal{F}} \left\lbrace 
                R(f) > \epsilon \wedge \hat{R}_n(f) = 0
                \right\rbrace
            \right]
            \\
            &\underset{\text{Union Bound}}{\le}
            \sum_{f\in \mathcal{F}}^{}
            \mathbb{P}\left[
                R(f) > \epsilon \wedge \hat{R}_n(f) = 0
            \right]
            \\
            &\le\left|
                \mathcal{F}
            \right|\exp(-n\epsilon)
        \end{align*}
    \section*{B.1.c}
        Let's assume that there exists instance where the bounds for what we derived on part (b) could be strict (I believe it should.), then we can re-arrange and get the expression that: 
        \begin{align*}\tag{B.1.c.1}\label{eqn:B.1.c.1}
            |\mathcal{F}|\exp(-\epsilon n) &\le \delta
            \\
            \ln(|\mathcal{F}|) - \epsilon n &\le \ln(\delta)
            \\
            -\epsilon n &\le \ln(\delta) - \ln(|\mathcal{F}|)
            \\
            \epsilon &\le \frac{\ln(\delta) - \ln(|\mathcal{F}|)}{-n}
            \\
            \epsilon &\le \frac{\ln(\frac{|\mathcal{F}|}{\delta})}
            {n}
        \end{align*}
        Therefore, the largest $\epsilon$ is $\frac{1}{n}\ln(|\mathcal{F}|/\delta)$
    \section*{B.1.d}
    We are proving the probability of the events $A \implies B$, where $A, B$ are some kind of probabilistic events, Using some math we have: $\mathbb{P}(A\implies B)  = 1 - \mathbb{P}\left(A\wedge \neg B\right)$, and in our case $A$ is $\hat{R}_n(\hat{f}) = 0$ and $B$ is $R(\hat{f}) - R(f^*)\le \frac{\ln(|\mathcal{F}|/\delta)}{n}$. 
    \\
    Let's get into the math and I will label the steps and explain them.
    \begin{align*}\tag{B.1.d.1}\label{eqn:B.1.d.1}
        \mathbb{P}\left[
            \widehat{R}_n(\hat{f}) = 0 \implies R(\hat{f}) - R(f^*) \le \frac{\ln(|\mathcal{F}|/\delta)}{n}
        \right] &\underset{(1)}{=} 
        1 - \mathbb{P}\left[
            \widehat{R}_n(\hat{f}) = 0 \wedge R(\hat{f}) - R(f^*) \ge \frac{\ln(|\mathcal{F}|/\delta)}{n}
        \right]
        \\
        &\underset{(2)}{\ge}
        1 - \mathbb{P}\left[
            \widehat{R}_n(\hat{f}) = 0 \wedge R(\hat{f}) \ge \frac{\ln(|\mathcal{F}|/\delta)}{n}
        \right]
        \\
        &\underset{(3)}{\ge}
        1 - \mathbb{P}\left[
            \widehat{R}_n(\hat{f}) = 0 \wedge R(\hat{f}) \ge \epsilon
        \right]
        \\
        &\underset{(4)}{\ge}
        1 - \mathbb{P}\left[
            \exists \hat{f} \in \mathcal{F}:\widehat{R}_n(\hat{f}) = 0 \wedge R(\hat{f}) \ge \epsilon
        \right]
        \\
        &\underset{\hyperref[eqn:B.1.b.3]{B.1.b.3}}{\ge}
        1 - |\mathcal{F}|\exp(-n\epsilon)
        \\
        &\ge 
        1 - \delta
    \end{align*}
    \begin{enumerate}
        \item[(1)] True becase: $A\implies B = \neg (A \wedge \neg B)$. 
        \item[(2)] True because $R(f^*) > 0$, meaning that $R(\hat{f}) - R(f^*) \le \frac{1}{n}\ln(|\mathcal{F}|/\delta)$ implies that $R(\hat{f}) \ge \frac{1}{n}\ln(|\mathcal{F}|/\delta)$, which implies that the latter is a subset of the former, Therefore its probability is going to be higher. Justifying the inequality. 
        \item[(3)] True because $\epsilon < \frac{1}{n} \ln(|\mathcal{F}|/\delta)$, and this is just what we proved in (c) of B.1. And because of this, whatever $\hat{f}$ that makes $\hat{f} \ge \frac{1}{n}\ln(|\mathcal{F}|/\delta)$ will make $R(\hat{f})\ge \epsilon$ as well, therefore the former is a subset of the latter, therefore the latter has a higher probability, justifying the inequality. 
        \item[(4)] The probability of the existence of at least one is higher than the probaility of the existence of any particular one, because the existence of any particular one has a prior that we chose that particular one to measure the imperical risk. 
    \end{enumerate}    
    The last one just by the definition of $\delta$. 

\end{document}
